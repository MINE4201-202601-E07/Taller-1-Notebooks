{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "515a72c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# carga de dataframes\n",
    "import pandas as pd\n",
    "\n",
    "PATH = 'movielens-20m-dataset/'\n",
    "genome_scores = pd.read_csv(PATH + 'genome_scores.csv')\n",
    "genome_tags = pd.read_csv(PATH + 'genome_tags.csv')\n",
    "link = pd.read_csv(PATH + 'link.csv')\n",
    "movie = pd.read_csv(PATH + 'movie.csv')\n",
    "rating = pd.read_csv(PATH + 'rating.csv')\n",
    "tag = pd.read_csv(PATH + 'tag.csv')\n",
    "\n",
    "dataframes = {\n",
    "    'genome_scores': genome_scores,\n",
    "    'genome_tags': genome_tags,\n",
    "    'link': link,\n",
    "    'movie': movie,\n",
    "    'rating': rating,\n",
    "    'tag': tag\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4466e3d6",
   "metadata": {},
   "source": [
    "## 1) Perfil del dataset y decisiones automáticas\n",
    "\n",
    "Este bloque inspecciona tamaños y sparsity, y define umbrales automáticos para entrenar un modelo user-based con Pearson usando `surprise`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "d3df0a06",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tamaño de dataframes:\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>dataframe</th>\n",
       "      <th>rows</th>\n",
       "      <th>cols</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>rating</td>\n",
       "      <td>20000263</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>genome_scores</td>\n",
       "      <td>11709768</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>tag</td>\n",
       "      <td>465564</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>link</td>\n",
       "      <td>27278</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>movie</td>\n",
       "      <td>27278</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>genome_tags</td>\n",
       "      <td>1128</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       dataframe      rows  cols\n",
       "0         rating  20000263     4\n",
       "1  genome_scores  11709768     3\n",
       "2            tag    465564     4\n",
       "3           link     27278     3\n",
       "4          movie     27278     3\n",
       "5    genome_tags      1128     2"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Perfil de ratings:\n",
      "ratings: 20,000,263\n",
      "users:   138,493\n",
      "items:   26,744\n",
      "sparsity: 0.994600\n",
      "\n",
      "Distribución ratings por usuario (quantiles):\n",
      "0.25     35.0\n",
      "0.50     68.0\n",
      "0.75    155.0\n",
      "0.90    334.0\n",
      "0.95    520.0\n",
      "\n",
      "Distribución ratings por item (quantiles):\n",
      "0.25       3.00\n",
      "0.50      18.00\n",
      "0.75     205.00\n",
      "0.90    1305.70\n",
      "0.95    3612.95\n",
      "\n",
      "Configuración automática elegida:\n",
      "- min_user_ratings: 93\n",
      "- min_item_ratings: 47\n",
      "- max_users: 8000\n",
      "- k_neighbors: 80\n",
      "- min_k: 3\n",
      "- max_test_eval: 20000\n",
      "- random_state: 42\n",
      "- approx_similarity_matrix_gb: 0.48\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "# Perfil general de todos los dataframes cargados\n",
    "summary_rows = []\n",
    "for name, df in dataframes.items():\n",
    "    summary_rows.append({\n",
    "        'dataframe': name,\n",
    "        'rows': len(df),\n",
    "        'cols': df.shape[1]\n",
    "    })\n",
    "\n",
    "summary_df = pd.DataFrame(summary_rows).sort_values('rows', ascending=False).reset_index(drop=True)\n",
    "print('Tamaño de dataframes:')\n",
    "display(summary_df)\n",
    "\n",
    "# Perfil específico de ratings\n",
    "ratings = rating[['userId', 'movieId', 'rating', 'timestamp']].copy()\n",
    "ratings['userId'] = ratings['userId'].astype(np.int32)\n",
    "ratings['movieId'] = ratings['movieId'].astype(np.int32)\n",
    "ratings['rating'] = ratings['rating'].astype(np.float32)\n",
    "\n",
    "n_ratings = len(ratings)\n",
    "n_users = ratings['userId'].nunique()\n",
    "n_items = ratings['movieId'].nunique()\n",
    "\n",
    "user_counts = ratings.groupby('userId').size()\n",
    "item_counts = ratings.groupby('movieId').size()\n",
    "\n",
    "sparsity = 1 - (n_ratings / (n_users * n_items))\n",
    "\n",
    "print('\\nPerfil de ratings:')\n",
    "print(f'ratings: {n_ratings:,}')\n",
    "print(f'users:   {n_users:,}')\n",
    "print(f'items:   {n_items:,}')\n",
    "print(f'sparsity: {sparsity:.6f}')\n",
    "print('\\nDistribución ratings por usuario (quantiles):')\n",
    "print(user_counts.quantile([0.25, 0.5, 0.75, 0.90, 0.95]).to_string())\n",
    "print('\\nDistribución ratings por item (quantiles):')\n",
    "print(item_counts.quantile([0.25, 0.5, 0.75, 0.90, 0.95]).to_string())\n",
    "\n",
    "# Decisiones automáticas según escala\n",
    "if n_ratings >= 10_000_000:\n",
    "    min_user_ratings = int(max(40, user_counts.quantile(0.60)))\n",
    "    min_item_ratings = int(max(40, item_counts.quantile(0.60)))\n",
    "    k_neighbors = 80\n",
    "elif n_ratings >= 2_000_000:\n",
    "    min_user_ratings = int(max(20, user_counts.quantile(0.50)))\n",
    "    min_item_ratings = int(max(20, item_counts.quantile(0.50)))\n",
    "    k_neighbors = 60\n",
    "else:\n",
    "    min_user_ratings = int(max(10, user_counts.quantile(0.40)))\n",
    "    min_item_ratings = int(max(10, item_counts.quantile(0.40)))\n",
    "    k_neighbors = 40\n",
    "\n",
    "min_user_ratings = max(5, min_user_ratings)\n",
    "min_item_ratings = max(5, min_item_ratings)\n",
    "\n",
    "# Límite de usuarios para evitar crash en User-User KNN (matriz UxU)\n",
    "TARGET_SIM_GB = 0.6\n",
    "MAX_USERS_BY_MEMORY = int(np.sqrt((TARGET_SIM_GB * (1024 ** 3)) / 8))\n",
    "MAX_USERS_HARD = 8000\n",
    "max_users = min(MAX_USERS_BY_MEMORY, MAX_USERS_HARD)\n",
    "\n",
    "# Tamaño máximo de test a evaluar para tiempos estables\n",
    "max_test_eval = 20000\n",
    "\n",
    "config = {\n",
    "    'min_user_ratings': min_user_ratings,\n",
    "    'min_item_ratings': min_item_ratings,\n",
    "    'max_users': max_users,\n",
    "    'k_neighbors': k_neighbors,\n",
    "    'min_k': 3,\n",
    "    'max_test_eval': max_test_eval,\n",
    "    'random_state': 42\n",
    "}\n",
    "\n",
    "est_sim_gb = (config['max_users'] ** 2 * 8) / (1024 ** 3)\n",
    "\n",
    "print('\\nConfiguración automática elegida:')\n",
    "for key, value in config.items():\n",
    "    print(f'- {key}: {value}')\n",
    "print(f\"- approx_similarity_matrix_gb: {est_sim_gb:.2f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "54ef506f",
   "metadata": {},
   "source": [
    "## 2) Filtrado y split temporal (leave-one-out)\n",
    "\n",
    "Se filtran usuarios/items poco activos y se toma la última interacción por usuario para test."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "3177dc50",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Después de filtrado/split:\n",
      "train ratings: 6,713,420\n",
      "test ratings:  8,000\n",
      "train users:   8,000\n",
      "train items:   10,724\n"
     ]
    }
   ],
   "source": [
    "# Filtrado por actividad\n",
    "user_counts = ratings['userId'].value_counts()\n",
    "item_counts = ratings['movieId'].value_counts()\n",
    "\n",
    "filtered = ratings[\n",
    "    ratings['userId'].isin(user_counts[user_counts >= config['min_user_ratings']].index)\n",
    "    & ratings['movieId'].isin(item_counts[item_counts >= config['min_item_ratings']].index)\n",
    "].copy()\n",
    "\n",
    "# Limitar usuarios para entrenamiento estable en user-user similarity\n",
    "if config['max_users'] is not None:\n",
    "    top_users = filtered['userId'].value_counts().head(config['max_users']).index\n",
    "    filtered = filtered[filtered['userId'].isin(top_users)].copy()\n",
    "\n",
    "filtered.sort_values(['userId', 'timestamp'], inplace=True)\n",
    "\n",
    "# Leave-one-out temporal: última interacción de cada usuario a test\n",
    "test_idx = filtered.groupby('userId').tail(1).index\n",
    "test_df = filtered.loc[test_idx, ['userId', 'movieId', 'rating']].copy()\n",
    "train_df = filtered.drop(test_idx)[['userId', 'movieId', 'rating']].copy()\n",
    "\n",
    "# Mantener solo test con usuarios e ítems presentes en train\n",
    "train_users = set(train_df['userId'].unique())\n",
    "train_items = set(train_df['movieId'].unique())\n",
    "test_df = test_df[\n",
    "    test_df['userId'].isin(train_users) &\n",
    "    test_df['movieId'].isin(train_items)\n",
    "].copy()\n",
    "\n",
    "# Submuestreo de test para evaluación más rápida/estable\n",
    "if len(test_df) > config['max_test_eval']:\n",
    "    test_df = test_df.sample(n=config['max_test_eval'], random_state=config['random_state'])\n",
    "\n",
    "print('Después de filtrado/split:')\n",
    "print(f\"train ratings: {len(train_df):,}\")\n",
    "print(f\"test ratings:  {len(test_df):,}\")\n",
    "print(f\"train users:   {train_df['userId'].nunique():,}\")\n",
    "print(f\"train items:   {train_df['movieId'].nunique():,}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cdd2390d",
   "metadata": {},
   "source": [
    "## 3) Modelo User-User Pearson con `surprise`\n",
    "\n",
    "Entrenamiento, evaluación y recomendaciones Top-N."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "e6ac320a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Resultado modelo Surprise (User-User Pearson):\n",
      "train users: 8,000 | train ratings: 6,713,420\n",
      "k_neighbors: 80 | min_k: 3\n",
      "Evaluados: 8,000 de 8,000\n",
      "RMSE: 0.8826\n",
      "MAE:  0.6853\n",
      "Coverage: 100.00%\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "import subprocess\n",
    "import importlib\n",
    "\n",
    "if importlib.util.find_spec('surprise') is None:\n",
    "    subprocess.check_call([sys.executable, '-m', 'pip', 'install', '-q', 'scikit-surprise'])\n",
    "\n",
    "from surprise import Dataset, Reader, KNNBasic\n",
    "\n",
    "reader = Reader(rating_scale=(0.5, 5.0))\n",
    "train_data = Dataset.load_from_df(train_df[['userId', 'movieId', 'rating']], reader)\n",
    "trainset = train_data.build_full_trainset()\n",
    "\n",
    "sim_options = {\n",
    "    'name': 'pearson',\n",
    "    'user_based': True\n",
    "}\n",
    "\n",
    "algo = KNNBasic(\n",
    "    k=config['k_neighbors'],\n",
    "    min_k=config['min_k'],\n",
    "    sim_options=sim_options,\n",
    "    verbose=False\n",
    ")\n",
    "algo.fit(trainset)\n",
    "\n",
    "# Evaluación en test\n",
    "y_true, y_pred = [], []\n",
    "for row in test_df.itertuples(index=False):\n",
    "    pred = algo.predict(uid=row.userId, iid=row.movieId, r_ui=row.rating)\n",
    "    y_true.append(float(row.rating))\n",
    "    y_pred.append(float(pred.est))\n",
    "\n",
    "y_true = np.array(y_true, dtype=np.float32)\n",
    "y_pred = np.array(y_pred, dtype=np.float32)\n",
    "\n",
    "rmse = float(np.sqrt(np.mean((y_true - y_pred) ** 2))) if len(y_true) else float('nan')\n",
    "mae = float(np.mean(np.abs(y_true - y_pred))) if len(y_true) else float('nan')\n",
    "coverage = float(len(y_pred) / len(test_df)) if len(test_df) else 0.0\n",
    "\n",
    "print('Resultado modelo Surprise (User-User Pearson):')\n",
    "print(f\"train users: {train_df['userId'].nunique():,} | train ratings: {len(train_df):,}\")\n",
    "print(f\"k_neighbors: {config['k_neighbors']} | min_k: {config['min_k']}\")\n",
    "print(f\"Evaluados: {len(y_true):,} de {len(test_df):,}\")\n",
    "print(f\"RMSE: {rmse:.4f}\")\n",
    "print(f\"MAE:  {mae:.4f}\")\n",
    "print(f\"Coverage: {coverage:.2%}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "ac439b29",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Top-10 recomendaciones para userId=118205\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>movieId</th>\n",
       "      <th>title</th>\n",
       "      <th>pred_rating</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>6985</td>\n",
       "      <td>Passion of Joan of Arc, The (Passion de Jeanne...</td>\n",
       "      <td>4.455542</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>93040</td>\n",
       "      <td>Civil War, The (1990)</td>\n",
       "      <td>4.427976</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>26073</td>\n",
       "      <td>Human Condition III, The (Ningen no joken III)...</td>\n",
       "      <td>4.402057</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>77658</td>\n",
       "      <td>Cosmos (1980)</td>\n",
       "      <td>4.397748</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>102217</td>\n",
       "      <td>Bill Hicks: Revelations (1993)</td>\n",
       "      <td>4.360630</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>40697</td>\n",
       "      <td>Babylon 5</td>\n",
       "      <td>4.351508</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>5690</td>\n",
       "      <td>Grave of the Fireflies (Hotaru no haka) (1988)</td>\n",
       "      <td>4.351008</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>60904</td>\n",
       "      <td>Heart of a Dog (Sobachye serdtse) (1988)</td>\n",
       "      <td>4.344930</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>668</td>\n",
       "      <td>Song of the Little Road (Pather Panchali) (1955)</td>\n",
       "      <td>4.277301</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>5498</td>\n",
       "      <td>Red Beard (Akahige) (1965)</td>\n",
       "      <td>4.276867</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   movieId                                              title  pred_rating\n",
       "0     6985  Passion of Joan of Arc, The (Passion de Jeanne...     4.455542\n",
       "1    93040                              Civil War, The (1990)     4.427976\n",
       "2    26073  Human Condition III, The (Ningen no joken III)...     4.402057\n",
       "3    77658                                      Cosmos (1980)     4.397748\n",
       "4   102217                     Bill Hicks: Revelations (1993)     4.360630\n",
       "5    40697                                          Babylon 5     4.351508\n",
       "6     5690     Grave of the Fireflies (Hotaru no haka) (1988)     4.351008\n",
       "7    60904           Heart of a Dog (Sobachye serdtse) (1988)     4.344930\n",
       "8      668   Song of the Little Road (Pather Panchali) (1955)     4.277301\n",
       "9     5498                         Red Beard (Akahige) (1965)     4.276867"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Top-N recomendaciones para un usuario de ejemplo\n",
    "sample_user = int(train_df['userId'].value_counts().index[0])\n",
    "\n",
    "seen = set(train_df.loc[train_df['userId'] == sample_user, 'movieId'])\n",
    "all_items = set(train_df['movieId'].unique())\n",
    "candidates = list(all_items - seen)\n",
    "\n",
    "scored = []\n",
    "for movie_id in candidates:\n",
    "    est = algo.predict(uid=sample_user, iid=int(movie_id)).est\n",
    "    scored.append((int(movie_id), float(est)))\n",
    "\n",
    "top_n = 10\n",
    "top_items = sorted(scored, key=lambda x: x[1], reverse=True)[:top_n]\n",
    "\n",
    "rec_df = pd.DataFrame(top_items, columns=['movieId', 'pred_rating'])\n",
    "rec_df = rec_df.merge(movie[['movieId', 'title']], on='movieId', how='left')\n",
    "\n",
    "print(f'Top-{top_n} recomendaciones para userId={sample_user}')\n",
    "display(rec_df[['movieId', 'title', 'pred_rating']])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d3540231",
   "metadata": {},
   "source": [
    "## 4) Exportar y cargar el modelo\n",
    "\n",
    "Guardar el modelo entrenado para reutilizarlo sin reentrenar."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "0cd1e9e7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Modelo guardado en: artifacts/surprise_user_user_pearson.pkl\n",
      "Metadata guardada en: artifacts/surprise_user_user_pearson_metadata.json\n"
     ]
    }
   ],
   "source": [
    "from pathlib import Path\n",
    "from surprise import dump\n",
    "import json\n",
    "\n",
    "model_dir = Path('artifacts')\n",
    "model_dir.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "model_path = model_dir / 'surprise_user_user_pearson.pkl'\n",
    "metadata_path = model_dir / 'surprise_user_user_pearson_metadata.json'\n",
    "\n",
    "# Guardar modelo Surprise\n",
    "dump.dump(str(model_path), algo=algo)\n",
    "\n",
    "metadata = {\n",
    "    'algorithm': 'KNNBasic',\n",
    "    'similarity': 'pearson',\n",
    "    'user_based': True,\n",
    "    'k_neighbors': int(config['k_neighbors']),\n",
    "    'min_k': int(config['min_k']),\n",
    "    'train_users': int(train_df['userId'].nunique()),\n",
    "    'train_items': int(train_df['movieId'].nunique()),\n",
    "    'train_ratings': int(len(train_df)),\n",
    "    'rmse': float(rmse),\n",
    "    'mae': float(mae),\n",
    "    'coverage': float(coverage)\n",
    "}\n",
    "\n",
    "with open(metadata_path, 'w', encoding='utf-8') as f:\n",
    "    json.dump(metadata, f, ensure_ascii=False, indent=2)\n",
    "\n",
    "print(f'Modelo guardado en: {model_path}')\n",
    "print(f'Metadata guardada en: {metadata_path}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "bbf819b7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Modelo cargado correctamente.\n",
      "Predicción de prueba -> userId=11, movieId=5971\n",
      "real=5.00, estimado=4.03\n"
     ]
    }
   ],
   "source": [
    "# Cargar modelo exportado y probar predicción\n",
    "from surprise import dump\n",
    "\n",
    "_, loaded_algo = dump.load('artifacts/surprise_user_user_pearson.pkl')\n",
    "\n",
    "sample_row = test_df.iloc[0]\n",
    "loaded_pred = loaded_algo.predict(\n",
    "    uid=int(sample_row['userId']),\n",
    "    iid=int(sample_row['movieId']),\n",
    "    r_ui=float(sample_row['rating'])\n",
    ")\n",
    "\n",
    "print('Modelo cargado correctamente.')\n",
    "print(f\"Predicción de prueba -> userId={int(sample_row['userId'])}, movieId={int(sample_row['movieId'])}\")\n",
    "print(f\"real={float(sample_row['rating']):.2f}, estimado={loaded_pred.est:.2f}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
